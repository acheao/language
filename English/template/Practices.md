I've been feeling a lot of panic and fear about this talk.

And not just for the normal reasons of public speaking, although that's there, too.

But it's also because I want to say something meaningful, and I've been overwhelmed by the enormity of what is happening right now.

And there's a particular set of circumstances which have also been feeding into my confusion and denial.

And that is because the last time that I stood on this stage, it led to a three-year legal battle, culminated in London's High Court, in which it felt like I was on trial for my life, because I was.

My career, my reputation, my finances, even my home was on the line.

All because I came here to warn you that I didn't think democracy was going to survive the technology that you're building, however incredible it is.

In fact, I was the person who almost didn't survive, and pretty much everything I was warning about is now coming true.

I can't sugarcoat it.

It's a bit of a headfuck.

25
00:01:27,852 --> 00:01:29,420
(Laughter)

26
00:01:30,287 --> 00:01:33,491
I have a lot of emotions
about coming here.

27
00:01:33,524 --> 00:01:38,028
And TED, also, I suspect,
is feeling them too.

28
00:01:38,329 --> 00:01:41,665
But what actually
I finally realized yesterday

29
00:01:41,665 --> 00:01:44,668
is that the denial and the confusion
that I've been feeling

30
00:01:44,702 --> 00:01:46,971
is maybe what you're feeling, too.

31
00:01:48,239 --> 00:01:51,709
I felt powerless for a really long time.

32
00:01:51,742 --> 00:01:54,612
So if that's what
you're feeling, I get it.

33
00:01:55,412 --> 00:01:59,250
But we have to act now.

34
00:01:59,583 --> 00:02:03,387
My alarm system is ringing again.

35
00:02:05,256 --> 00:02:07,658
There are things that we can do.

36
00:02:08,826 --> 00:02:11,262
In my case, I survived.

37
00:02:11,295 --> 00:02:12,630
And you will too.

38
00:02:12,663 --> 00:02:15,566
But it's by learning how to fight back.

39
00:02:16,400 --> 00:02:18,569
This is my guide,

40
00:02:18,569 --> 00:02:22,239
and it has to start with naming it.

41
00:02:24,074 --> 00:02:25,476
It's a coup.

42
00:02:26,143 --> 00:02:29,246
I know you probably don't want
to hear that, and especially here,

43
00:02:29,246 --> 00:02:31,215
but we can’t fight it if we can’t see it.

44
00:02:31,215 --> 00:02:33,651
And we can’t see it if we don’t name it.

45
00:02:34,118 --> 00:02:40,891
(Applause)

46
00:02:41,692 --> 00:02:45,930
The Russian and American presidents
are now speaking the same words.

47
00:02:46,764 --> 00:02:48,933
They are telling the same lies.

48
00:02:49,633 --> 00:02:55,039
We are watching the collapse
of the international order in real time.

49
00:02:55,072 --> 00:02:57,741
And this is just the start.

50
00:02:58,842 --> 00:03:00,578
Coups are like concrete.

51
00:03:00,578 --> 00:03:02,780
When they stop moving, they set.

52
00:03:03,881 --> 00:03:06,817
It is already later than we think.

53
00:03:07,218 --> 00:03:10,955
This image, some of you
in this room might know these people.

54
00:03:10,988 --> 00:03:13,958
I call it tech bros in hostage situations.

55
00:03:13,991 --> 00:03:15,893
It's a message to you.

56
00:03:15,893 --> 00:03:18,028
This is Putin's playbook.

57
00:03:19,129 --> 00:03:22,466
He allows a business elite
to make untold riches

58
00:03:22,499 --> 00:03:25,402
in exchange for absolute loyalty.

59
00:03:26,637 --> 00:03:29,306
Some people are calling this oligarchy,

60
00:03:29,340 --> 00:03:31,675
but it's actually bigger than that.

61
00:03:32,643 --> 00:03:35,179
These are global platforms.

62
00:03:36,547 --> 00:03:38,349
It's broligarchy.

63
00:03:38,382 --> 00:03:40,484
[Tech bros   oligarchy = broligarchy]

64
00:03:40,484 --> 00:03:42,186
(Laughter and murmuring)

65
00:03:42,886 --> 00:03:47,458
(Applause)

66
00:03:48,492 --> 00:03:51,996
There is an alignment of interests

67
00:03:52,029 --> 00:03:55,666
that runs through Silicon Valley

68
00:03:55,699 --> 00:03:59,536
to what is now a coming autocracy.

69
00:04:01,538 --> 00:04:06,210
It's a type of power that the world
has never seen before.

70
00:04:07,144 --> 00:04:08,512
[Follow the data]

71
00:04:09,580 --> 00:04:11,048
It's always the data.

72
00:04:12,149 --> 00:04:14,952
It's the crack cocaine of Silicon Valley.

73
00:04:15,753 --> 00:04:18,088
You know, the first thing
that Elon Musk did

74
00:04:18,122 --> 00:04:21,659
was to send his cyber troops
into the US Treasury

75
00:04:21,659 --> 00:04:23,360
to get access to the data.

76
00:04:23,394 --> 00:04:24,728
That is not a coincidence.

77
00:04:24,762 --> 00:04:26,363
It's a hack.

78
00:04:26,397 --> 00:04:30,434
That data is now feeding AIs
that are choosing who to sack

79
00:04:30,434 --> 00:04:31,902
and who to replace --

80
00:04:31,935 --> 00:04:33,971
Sorry -- eliminate fraud and waste.

81
00:04:34,705 --> 00:04:36,607
(Laughter)

82
00:04:36,640 --> 00:04:39,176
When we broke the 
Cambridge Analytica story

83
00:04:39,209 --> 00:04:43,180
about the harvesting [of]
87 million people’s Facebook data,

84
00:04:43,213 --> 00:04:45,783
people freaked out, rightly.

85
00:04:46,550 --> 00:04:49,653
[That] is chicken feed compared to [this].

86
00:04:50,287 --> 00:04:51,855
But it is the blueprint.

87
00:04:53,290 --> 00:04:54,892
It's always the data.

88
00:04:56,460 --> 00:04:58,162
Which is why it's so important

89
00:04:58,195 --> 00:05:01,031
that you start thinking
about your private life.

90
00:05:01,031 --> 00:05:03,500
The broligarchy doesn't
want you to have one.

91
00:05:03,500 --> 00:05:08,505
This is the old headquarters
of the East German secret police.

92
00:05:09,373 --> 00:05:14,411
They kept detailed files
on almost one in three of their citizens.

93
00:05:15,479 --> 00:05:19,383
That is nothing compared
to what Google has

94
00:05:19,416 --> 00:05:21,385
on every single one of us,

95
00:05:21,418 --> 00:05:23,821
and hundreds of other companies.

96
00:05:25,456 --> 00:05:30,160
The entire business model
of Silicon Valley is surveillance.

97
00:05:30,894 --> 00:05:34,365
It harvests our data
in order to sell us stuff.

98
00:05:35,432 --> 00:05:40,537
We are already living inside
the architecture of totalitarianism.

99
00:05:40,571 --> 00:05:41,705
(Cheers)

100
00:05:42,072 --> 00:05:44,274
(Applause)

101
00:05:44,308 --> 00:05:48,345
It may not have been deliberate,

102
00:05:48,379 --> 00:05:52,850
but we now have to start acting
as if we live in East Germany,

103
00:05:53,550 --> 00:05:56,286
and Instagram is the Stasi.

104
00:05:58,856 --> 00:06:01,392
Politics is downstream from culture.

105
00:06:01,825 --> 00:06:05,195
So I actually learned this from somebody

106
00:06:05,229 --> 00:06:09,199
who I think of as one of the great
philosophers of our age,

107
00:06:09,233 --> 00:06:10,367
Steve Bannon.

108
00:06:10,401 --> 00:06:11,835
(Laughter)

109
00:06:11,835 --> 00:06:13,937
He actually stole it from somebody else.

110
00:06:15,873 --> 00:06:20,010
But it's not politicians
who have the power.

111
00:06:20,010 --> 00:06:21,245
He knows that.

112
00:06:21,278 --> 00:06:24,481
It's why he's a podcast bro, these days.

113
00:06:25,649 --> 00:06:29,853
But culture now is just
what's next on your phone.

114
00:06:30,821 --> 00:06:32,289
And that's AI.

115
00:06:32,322 --> 00:06:35,025
Culture is AI now.

116
00:06:35,659 --> 00:06:37,594
And forget the killer robots.

117
00:06:37,628 --> 00:06:42,866
If you want to know what
the first great AI apocalypse is,

118
00:06:42,900 --> 00:06:44,568
we're already living it.

119
00:06:44,568 --> 00:06:47,204
It's total information collapse.

120
00:06:48,539 --> 00:06:53,010
And if you take one thing
only away from this talk,

121
00:06:53,010 --> 00:06:56,213
it's politics is technology now.

122
00:06:57,214 --> 00:07:00,617
And that's why everybody in this room,
you can't look away.

123
00:07:01,618 --> 00:07:04,455
It's why your CEOs have been taken captive

124
00:07:04,488 --> 00:07:06,890
and are paraded on TV like hostages.

125
00:07:08,525 --> 00:07:11,128
But you, you have a choice.

126
00:07:13,864 --> 00:07:17,334
So Trump, he calls the press
the enemies of the people.

127
00:07:17,367 --> 00:07:20,337
And he probably doesn't even know
that he's quoting Stalin.

128
00:07:22,039 --> 00:07:25,843
So what happened to me is a playbook,

129
00:07:25,843 --> 00:07:30,481
and it's now coming
for all sorts of other people.

130
00:07:30,481 --> 00:07:33,984
It was actually a friend of this guy
who came after me.

131
00:07:34,017 --> 00:07:35,252
This is Nigel Farage.

132
00:07:35,252 --> 00:07:36,620
He's a Brexit funder.

133
00:07:36,653 --> 00:07:41,191
I'm not going to go super
into the details.

134
00:07:42,893 --> 00:07:47,464
But 19 press-freedom organizations

135
00:07:47,464 --> 00:07:50,000
called the lawsuit against me a SLAPP.

136
00:07:50,467 --> 00:07:55,272
That means it’s a Strategic
Litigation Against Public Participation.

137
00:07:56,106 --> 00:07:57,975
A really long-winded way of saying

138
00:07:58,008 --> 00:08:01,345
it's using law as a weapon
to shut people up.

139
00:08:01,378 --> 00:08:03,947
Not just journalists,
but other public people, too.

140
00:08:03,981 --> 00:08:05,215
And it works.

141
00:08:06,216 --> 00:08:09,486
I just wanted to tell you
about one aspect of the litigation,

142
00:08:09,520 --> 00:08:11,522
which I found terrifying.

143
00:08:11,555 --> 00:08:13,624
And that was the data harvesting.

144
00:08:14,925 --> 00:08:17,961
There's this quote you may know,
it's Cardinal Richelieu,

145
00:08:17,995 --> 00:08:19,396
"If you give me six lines

146
00:08:19,429 --> 00:08:22,132
written by the hand
of the most honest of men,

147
00:08:22,165 --> 00:08:25,536
I will find something
in them which will hang him."

148
00:08:26,737 --> 00:08:28,272
In my case,

149
00:08:28,305 --> 00:08:31,275
the first forensic searches
of my phone and laptop

150
00:08:31,308 --> 00:08:34,778
yielded 40,000 pieces of data.

151
00:08:35,445 --> 00:08:38,782
It was my messages, my emails,

152
00:08:38,815 --> 00:08:41,919
my voice memos, my personal life.

153
00:08:42,719 --> 00:08:45,055
And the whole thing about this,

154
00:08:45,088 --> 00:08:48,025
the attack which came for me,
was really personal.

155
00:08:48,025 --> 00:08:53,330
Because the thing about this litigation
is only one part of the playbook.

156
00:08:53,330 --> 00:08:58,368
It was also this sort of massive
online campaign of abuse,

157
00:08:58,402 --> 00:09:02,072
which is just day after day,

158
00:09:02,072 --> 00:09:04,908
after day, after day.

159
00:09:04,942 --> 00:09:10,714
Because my most unforgivable
crime was reporting while female.

160
00:09:11,882 --> 00:09:13,984
It was a digital witch burning.

161
00:09:16,687 --> 00:09:20,524
And I believe that this man came
after me personally,

162
00:09:20,557 --> 00:09:22,526
not at "The Guardian" and not TED,

163
00:09:22,559 --> 00:09:24,895
it was because I looked
like the weakest link.

164
00:09:26,330 --> 00:09:27,664
But he was wrong.

165
00:09:29,266 --> 00:09:36,039
(Cheers and applause)

166
00:09:37,074 --> 00:09:40,677
30,000 people rose up to support me.

167
00:09:41,411 --> 00:09:46,416
They contributed almost
a million pounds to a legal defense fund.

168
00:09:46,450 --> 00:09:49,519
Because they saw a bully
trying to crush me,

169
00:09:49,519 --> 00:09:51,655
and they would not let it stand.

170
00:09:53,590 --> 00:09:57,260
And it always makes me
emotional when I think about that.

171
00:09:57,294 --> 00:09:59,730
I just heard somebody was saying,
the camera person,

172
00:09:59,763 --> 00:10:02,432
I don't know where they are, contributed.

173
00:10:05,369 --> 00:10:10,374
This whole talk is actually my gratitude
towards everybody who did that.

174
00:10:11,575 --> 00:10:15,145
But it's also why I know
about what we have to do next.

175
00:10:15,579 --> 00:10:17,648
You know, Trump is suing
news organizations,

176
00:10:17,681 --> 00:10:19,216
and every day they're settling.

177
00:10:19,249 --> 00:10:21,785
These are big corporates
with corporate interests.

178
00:10:22,119 --> 00:10:24,054
Not everybody can stand up to power,

179
00:10:24,087 --> 00:10:28,992
but there are people who are doing it,
and we can support them.

180
00:10:29,026 --> 00:10:32,095
We have to have
each other’s backs right now.

181
00:10:32,129 --> 00:10:34,998
Because we are the cavalry now.

182
00:10:35,932 --> 00:10:37,934
You know, this is really important to me,

183
00:10:37,968 --> 00:10:41,505
but I spoke to a UK libel lawyer
before this talk.

184
00:10:42,172 --> 00:10:46,576
I want to say that there is
an awful lot of facts set down

185
00:10:46,610 --> 00:10:49,246
in a High Court judgment,

186
00:10:49,279 --> 00:10:53,316
and we're actually taking the case now
to the European Court of Human Rights.

187
00:10:53,350 --> 00:10:56,820
We're testing the UK on its laws
around freedom of expression.

188
00:10:59,322 --> 00:11:00,524
So look after facts.

189
00:11:00,557 --> 00:11:02,259
You'll miss them when they've gone.

190
00:11:02,259 --> 00:11:03,460
This is Wayback Machine.

191
00:11:03,493 --> 00:11:04,628
Give them money,

192
00:11:04,661 --> 00:11:08,165
they're trying to preserve the internet
as it's being deleted day by day.

193
00:11:08,198 --> 00:11:12,602
(Applause)

194
00:11:12,602 --> 00:11:15,605
History is our best chance
of getting out of this.

195
00:11:16,573 --> 00:11:18,508
You know, you probably know this phrase,

196
00:11:18,508 --> 00:11:20,377
"Do not obey in advance."

197
00:11:20,410 --> 00:11:23,880
That's Tim Snyder, who's a historian
of authoritarianism.

198
00:11:23,914 --> 00:11:26,483
We now are in techno-authoritarianism.

199
00:11:26,483 --> 00:11:29,586
We have to learn how to digitally disobey.

200
00:11:29,586 --> 00:11:32,789
That can be as simple
as the dropdown box.

201
00:11:32,789 --> 00:11:34,524
Don't accept the cookies,

202
00:11:34,558 --> 00:11:36,393
don't give your real name,

203
00:11:36,426 --> 00:11:39,663
download Signal,
the encrypted messaging app.

204
00:11:39,696 --> 00:11:40,931
Don’t bomb Yemen,

205
00:11:40,931 --> 00:11:44,668
don't add the editor
of "The Atlantic" to your group chats.

206
00:11:44,668 --> 00:11:46,503
(Laughter)

207
00:11:49,639 --> 00:11:51,675
Don't experiment on children.

208
00:11:52,075 --> 00:11:53,610
You know, social mores change.

209
00:11:53,643 --> 00:11:56,580
We don't send children
down coal mines anymore.

210
00:11:56,980 --> 00:11:58,181
And in years to come,

211
00:11:58,215 --> 00:12:02,018
allowing your child to be
data-harvested from birth

212
00:12:02,052 --> 00:12:04,221
will be considered child abuse.

213
00:12:05,122 --> 00:12:08,725
You didn't know, but now you do.

214
00:12:09,292 --> 00:12:12,028
Privacy is power.

215
00:12:14,364 --> 00:12:16,333
And we have more of it than we think.

216
00:12:17,267 --> 00:12:20,904
I had this little epiphany yesterday
in which I realized, actually,

217
00:12:20,937 --> 00:12:22,973
the moments when I felt most powerless

218
00:12:23,006 --> 00:12:26,510
were the moments that I felt
I was actually most powerful.

219
00:12:27,010 --> 00:12:30,046
It was because my journalism had impact.

220
00:12:31,081 --> 00:12:32,916
They want us to feel powerless.

221
00:12:32,949 --> 00:12:34,584
That's the plan.

222
00:12:34,618 --> 00:12:35,852
There is so much, though,

223
00:12:35,852 --> 00:12:39,022
that we can learn from people
who've been through this before.

224
00:12:39,422 --> 00:12:40,891
Alexei Navalny,

225
00:12:40,924 --> 00:12:42,893
the leader of the Russian opposition,

226
00:12:42,926 --> 00:12:46,630
he always talked about a beautiful
Russia of the future.

227
00:12:46,663 --> 00:12:48,131
He painted a vision.

228
00:12:48,899 --> 00:12:53,069
There is a beautiful
internet of the future,

229
00:12:53,069 --> 00:12:56,773
free from corporate capture
and data tracking.

230
00:12:57,407 --> 00:12:59,042
We can build it.

231
00:12:59,943 --> 00:13:02,512
It is going to take a movement.

232
00:13:02,546 --> 00:13:06,850
But we can learn from movements
that there have been before us.

233
00:13:07,417 --> 00:13:11,655
This is my colleagues and I
on strike in December

234
00:13:11,655 --> 00:13:14,825
because my news
organization, "The Guardian,"

235
00:13:14,858 --> 00:13:20,463
decided to sell our corner of it,
“The Observer,” the Sunday title.

236
00:13:20,463 --> 00:13:23,700
And it was a battle we really
didn’t need at this time,

237
00:13:23,733 --> 00:13:25,335
and we didn’t actually win,

238
00:13:25,802 --> 00:13:30,173
but you know, you can’t win every battle.

239
00:13:30,207 --> 00:13:33,844
But you definitely won’t win
if you don’t fight.

240
00:13:33,844 --> 00:13:38,815
(Applause)

241
00:13:38,849 --> 00:13:41,818
So I want to leave you with this.

242
00:13:42,219 --> 00:13:45,922
This is ChatGPT

243
00:13:45,956 --> 00:13:50,260
writing a TED Talk
in the style of Carole Cadwalladr.

244
00:13:51,828 --> 00:13:54,231
And it is creepily plausible.

245
00:13:55,365 --> 00:13:56,600
But what it doesn't know,

246
00:13:56,600 --> 00:14:00,003
because AI is actually as dumb as a rock,

247
00:14:00,036 --> 00:14:03,139
is that I am going to turn to Sam Altman,

248
00:14:03,139 --> 00:14:06,309
who is coming here, a TED speaker,

249
00:14:06,343 --> 00:14:09,212
and say that this does not belong to you.

250
00:14:11,314 --> 00:14:15,752
ChatGPT has been trained on my IP,

251
00:14:15,785 --> 00:14:18,855
my labor, my personal data.

252
00:14:18,889 --> 00:14:24,461
(Applause and cheers)

253
00:14:24,494 --> 00:14:27,330
And I did not consent.

254
00:14:28,932 --> 00:14:31,601
You know, "The Guardian"
has effectively got rid

255
00:14:31,601 --> 00:14:33,536
of more than 100 journalists.

256
00:14:33,536 --> 00:14:36,106
We actually leave the building next week.

257
00:14:37,173 --> 00:14:38,642
And shortly afterwards,

258
00:14:38,675 --> 00:14:42,279
it signed a syndication deal with OpenAI.

259
00:14:43,446 --> 00:14:45,382
Or, as I think of it,

260
00:14:45,382 --> 00:14:47,083
it married its rapist.

261
00:14:49,853 --> 00:14:51,821
But I do not consent.

262
00:14:52,222 --> 00:14:55,892
And while we still have
copyright laws in my country,

263
00:14:55,926 --> 00:14:58,929
UK government is trying
to tear them up at the moment

264
00:14:58,962 --> 00:15:01,898
in order to suck up
to Silicon Valley and Trump.

265
00:15:01,898 --> 00:15:03,833
But while we have them, use them.

266
00:15:04,301 --> 00:15:07,003
Because what is happening to my industry

267
00:15:07,037 --> 00:15:08,772
is happening to yours, too.

268
00:15:09,506 --> 00:15:11,241
And it's more than theft.

269
00:15:11,775 --> 00:15:13,410
It's a violation.

270
00:15:13,777 --> 00:15:16,513
Data rights are human rights.

271
00:15:18,748 --> 00:15:23,353
(Applause)

272
00:15:23,954 --> 00:15:25,689
In 2019,

273
00:15:25,722 --> 00:15:30,427
I came here, and I called out
the gods of Silicon Valley.

274
00:15:31,895 --> 00:15:33,063
I was wrong.

275
00:15:34,230 --> 00:15:39,369
Sam Altman, Mark Zuckerberg, Elon Musk,

276
00:15:39,402 --> 00:15:41,671
you are not gods.

277
00:15:41,705 --> 00:15:44,140
You are men, and you are careless.

278
00:15:45,542 --> 00:15:52,449
(Applause and cheers)

279
00:15:53,450 --> 00:15:57,520
You think that by allying
yourself with an autocrat

280
00:15:57,554 --> 00:15:59,656
you will be protected.

281
00:15:59,656 --> 00:16:01,591
That's not how history works.

282
00:16:01,624 --> 00:16:04,060
It's not even how oligarchy works.

283
00:16:04,060 --> 00:16:06,196
This is Mikhail Khodorkovsky.

284
00:16:06,229 --> 00:16:10,000
He was an oligarch
until he was sent to Siberia,

285
00:16:10,033 --> 00:16:12,102
to prison for 10 years,

286
00:16:12,135 --> 00:16:13,970
after Putin tired of him.

287
00:16:15,372 --> 00:16:18,241
You are sucking up to a tyrant ...

288
00:16:20,577 --> 00:16:22,712
who is trying to destroy the laws

289
00:16:22,712 --> 00:16:25,115
who made your businesses possible.

290
00:16:26,716 --> 00:16:28,618
You are collaborators.

291
00:16:29,819 --> 00:16:35,058
You are complicit in a regime
of fear and cruelty.

292
00:16:36,259 --> 00:16:37,994
But the rest of us,

293
00:16:38,028 --> 00:16:41,464
we all here, we have a choice.

294
00:16:43,767 --> 00:16:47,203
I chose to come back to TED

295
00:16:47,237 --> 00:16:52,575
because I'm reclaiming my story, my words.

296
00:16:52,675 --> 00:16:59,682
(Cheers and applause) 

297
00:17:03,553 --> 00:17:06,823
We are not powerless.

298
00:17:07,924 --> 00:17:11,828
The 30,000 people who supported me

299
00:17:11,861 --> 00:17:15,265
proved that -- we are not powerless.

300
00:17:15,999 --> 00:17:19,602
Because we know who we are,
and we know what we stand for.

301
00:17:20,503 --> 00:17:23,973
And my question to Silicon Valley is,

302
00:17:23,973 --> 00:17:25,141
do you?

303
00:17:26,810 --> 00:17:27,977
Thank you.

304
00:17:28,011 --> 00:17:34,951
(Cheers and applause)